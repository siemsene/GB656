{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7daa631e-ad33-411c-9ccd-5f4def925245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Data/Tweets.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc9c45d7-62cb-495a-b664-5155027ec9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline_sentiment\n",
      "negative    9178\n",
      "neutral     3099\n",
      "positive    2363\n",
      "Name: count, dtype: int64\n",
      "                                                text airline_sentiment  \\\n",
      "0                @VirginAmerica What @dhepburn said.           neutral   \n",
      "1  @VirginAmerica plus you've added commercials t...          positive   \n",
      "2  @VirginAmerica I didn't today... Must mean I n...           neutral   \n",
      "3  @VirginAmerica it's really aggressive to blast...          negative   \n",
      "4  @VirginAmerica and it's a really big bad thing...          negative   \n",
      "\n",
      "   sentiment_label  \n",
      "0                1  \n",
      "1                2  \n",
      "2                1  \n",
      "3                0  \n",
      "4                0  \n"
     ]
    }
   ],
   "source": [
    "# Keep only the relevant columns: 'text' for the tweet and 'airline_sentiment' for the sentiment\n",
    "df = df[['text', 'airline_sentiment']]\n",
    "\n",
    "# Display the value counts of sentiment labels\n",
    "print(df['airline_sentiment'].value_counts())\n",
    "\n",
    "# Map the sentiments to numerical labels: negative = 0, neutral = 1, positive = 2\n",
    "df['sentiment_label'] = df['airline_sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2})\n",
    "\n",
    "# Display the first few rows of the processed dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42146e78-2b97-45cb-8175-4f44e599da56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       aa  aaaand  aaadvantage  aaalwayslate  aaba  aacom  aacustomerservice  \\\n",
      "0       0       0            0             0     0      0                  0   \n",
      "1       0       0            0             0     0      0                  0   \n",
      "2       0       0            0             0     0      0                  0   \n",
      "3       0       0            0             0     0      0                  0   \n",
      "4       0       0            0             0     0      0                  0   \n",
      "...    ..     ...          ...           ...   ...    ...                ...   \n",
      "14635   0       0            0             0     0      0                  0   \n",
      "14636   0       0            0             0     0      0                  0   \n",
      "14637   0       0            0             0     0      0                  0   \n",
      "14638   0       0            0             0     0      0                  0   \n",
      "14639   0       0            0             0     0      0                  0   \n",
      "\n",
      "       aadavantage  aadelay  aadfw  ...  zj  zkatcher  zombie  zone  zoom  \\\n",
      "0                0        0      0  ...   0         0       0     0     0   \n",
      "1                0        0      0  ...   0         0       0     0     0   \n",
      "2                0        0      0  ...   0         0       0     0     0   \n",
      "3                0        0      0  ...   0         0       0     0     0   \n",
      "4                0        0      0  ...   0         0       0     0     0   \n",
      "...            ...      ...    ...  ...  ..       ...     ...   ...   ...   \n",
      "14635            0        0      0  ...   0         0       0     0     0   \n",
      "14636            0        0      0  ...   0         0       0     0     0   \n",
      "14637            0        0      0  ...   0         0       0     0     0   \n",
      "14638            0        0      0  ...   0         0       0     0     0   \n",
      "14639            0        0      0  ...   0         0       0     0     0   \n",
      "\n",
      "       zrh  zrhairport  zuke  zurich  zurichnew  \n",
      "0        0           0     0       0          0  \n",
      "1        0           0     0       0          0  \n",
      "2        0           0     0       0          0  \n",
      "3        0           0     0       0          0  \n",
      "4        0           0     0       0          0  \n",
      "...    ...         ...   ...     ...        ...  \n",
      "14635    0           0     0       0          0  \n",
      "14636    0           0     0       0          0  \n",
      "14637    0           0     0       0          0  \n",
      "14638    0           0     0       0          0  \n",
      "14639    0           0     0       0          0  \n",
      "\n",
      "[14640 rows x 12473 columns]\n",
      "(14640, 12473)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "# Load spaCy's English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Custom function for text cleaning\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and numbers (optional)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    # Tokenize the text using spaCy, remove stop words, and lemmatize\n",
    "    doc = nlp(text)\n",
    "    cleaned_tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    \n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Sample dataset\n",
    "corpus = df['text']\n",
    "\n",
    "# Clean the corpus\n",
    "cleaned_corpus = [clean_text(doc) for doc in corpus]\n",
    "\n",
    "# Initialize CountVectorizer (after cleaning the text)\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the cleaned corpus\n",
    "X = vectorizer.fit_transform(cleaned_corpus)\n",
    "\n",
    "# Target labels\n",
    "y = df['sentiment_label'].values\n",
    "\n",
    "# Convert the result into a DataFrame for better readability (optional)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the result\n",
    "print(df)\n",
    "\n",
    "print(X.shape)  # Shape of the feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399be283-c7be-41a9-822c-8037d2f03992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 79.54%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.88      1889\n",
      "     neutral       0.60      0.55      0.58       580\n",
      "    positive       0.75      0.69      0.72       459\n",
      "\n",
      "    accuracy                           0.80      2928\n",
      "   macro avg       0.74      0.71      0.72      2928\n",
      "weighted avg       0.79      0.80      0.79      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the dataset into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model on the BoW representation\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['negative', 'neutral', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d68f7fda-8830-441c-8082-a734409dd677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: The flight was delayed by 2 hours. Terrible experience! \n",
      "Predicted Sentiment: negative\n",
      "\n",
      "Tweet: Great service, I loved the extra legroom in business class. \n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Tweet: The flight was fine, nothing special. \n",
      "Predicted Sentiment: negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example tweets to predict sentiment for\n",
    "new_tweets = [\n",
    "    \"The flight was delayed by 2 hours. Terrible experience!\",\n",
    "    \"Great service, I loved the extra legroom in business class.\",\n",
    "    \"The flight was fine, nothing special.\"\n",
    "]\n",
    "\n",
    "new_cleaned_corpus = [clean_text(doc) for doc in new_tweets]\n",
    "\n",
    "# Convert the new tweets to the BoW representation\n",
    "new_X = vectorizer.transform(new_cleaned_corpus)\n",
    "\n",
    "# Predict sentiment for the new tweets\n",
    "new_predictions = clf.predict(new_X)\n",
    "\n",
    "# Map the predictions back to sentiment labels\n",
    "predicted_sentiments = ['negative' if pred == 0 else 'neutral' if pred == 1 else 'positive' for pred in new_predictions]\n",
    "\n",
    "# Display the results\n",
    "for tweet, sentiment in zip(new_tweets, predicted_sentiments):\n",
    "    print(f\"Tweet: {tweet} \\nPredicted Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490320a-7653-40fc-9e43-2ff1a4652b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
