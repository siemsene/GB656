{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c70d232-fa31-46f0-86b2-c0079c7dc8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
      "0  570306133677760513           neutral                        1.0000   \n",
      "1  570301130888122368          positive                        0.3486   \n",
      "2  570301083672813571           neutral                        0.6837   \n",
      "3  570301031407624196          negative                        1.0000   \n",
      "4  570300817074462722          negative                        1.0000   \n",
      "\n",
      "  negativereason  negativereason_confidence         airline  \\\n",
      "0            NaN                        NaN  Virgin America   \n",
      "1            NaN                     0.0000  Virgin America   \n",
      "2            NaN                        NaN  Virgin America   \n",
      "3     Bad Flight                     0.7033  Virgin America   \n",
      "4     Can't Tell                     1.0000  Virgin America   \n",
      "\n",
      "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
      "0                    NaN     cairdin                 NaN              0   \n",
      "1                    NaN    jnardino                 NaN              0   \n",
      "2                    NaN  yvonnalynn                 NaN              0   \n",
      "3                    NaN    jnardino                 NaN              0   \n",
      "4                    NaN    jnardino                 NaN              0   \n",
      "\n",
      "                                                text tweet_coord  \\\n",
      "0                @VirginAmerica What @dhepburn said.         NaN   \n",
      "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
      "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
      "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
      "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
      "\n",
      "               tweet_created tweet_location               user_timezone  \n",
      "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
      "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
      "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
      "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
      "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  \n",
      "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
      "       'negativereason', 'negativereason_confidence', 'airline',\n",
      "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
      "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
      "       'tweet_location', 'user_timezone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Data/Tweets.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Check the columns available in the dataset\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef7b513-9bd2-4707-8d6f-e126f680d7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline_sentiment\n",
      "negative    9178\n",
      "neutral     3099\n",
      "positive    2363\n",
      "Name: count, dtype: int64\n",
      "                                                text airline_sentiment  \\\n",
      "0                @VirginAmerica What @dhepburn said.           neutral   \n",
      "1  @VirginAmerica plus you've added commercials t...          positive   \n",
      "2  @VirginAmerica I didn't today... Must mean I n...           neutral   \n",
      "3  @VirginAmerica it's really aggressive to blast...          negative   \n",
      "4  @VirginAmerica and it's a really big bad thing...          negative   \n",
      "\n",
      "   sentiment_label  \n",
      "0                1  \n",
      "1                2  \n",
      "2                1  \n",
      "3                0  \n",
      "4                0  \n"
     ]
    }
   ],
   "source": [
    "# Keep only the relevant columns: 'text' for the tweet and 'airline_sentiment' for the sentiment\n",
    "df = df[['text', 'airline_sentiment']]\n",
    "\n",
    "# Display the value counts of sentiment labels\n",
    "print(df['airline_sentiment'].value_counts())\n",
    "\n",
    "# Map the sentiments to numerical labels: negative = 0, neutral = 1, positive = 2\n",
    "df['sentiment_label'] = df['airline_sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2})\n",
    "\n",
    "# Display the first few rows of the processed dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196ec17e-4952-4558-9bfc-5750dfecadd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7f5a17db514c2e8dd2c6831d39f4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siems\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\siems\\.cache\\huggingface\\hub\\models--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4a7dcea90e43b6bcfaa427301b1005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d94696ceae4384bf2575c126c6bb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4edbc48d9a4660ad1f2a9737bfd9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850309c1b2d045d28c69e3f0ce0fa96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a86931d8fc74ad59ad4aa254803d553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Embedding Tweets: 100%|████████████████████████████████████| 14640/14640 [37:42<00:00,  6.47tweet/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the pre-trained RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "# Set the model to evaluation mode (important for inference)\n",
    "model.eval()\n",
    "\n",
    "# Function to generate embeddings from RoBERTa\n",
    "def get_roberta_embeddings(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    \n",
    "    # Pass the tokens through RoBERTa without computing gradients (inference mode)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # The hidden states (embeddings) from RoBERTa\n",
    "    last_hidden_state = outputs.last_hidden_state  # Shape: (batch_size, sequence_length, hidden_size)\n",
    "    \n",
    "    # Use the [CLS] token embedding as the sentence embedding (position 0 in the sequence)\n",
    "    cls_embedding = last_hidden_state[:, 0, :].squeeze().numpy()  # Shape: (hidden_size,)\n",
    "    \n",
    "    return cls_embedding\n",
    "\n",
    "# Convert all tweets to RoBERTa embeddings\n",
    "#df['embeddings'] = df['text'].apply(get_bert_embeddings)\n",
    "embeddings = []\n",
    "for text in tqdm(df['text'], desc=\"Embedding Tweets\", unit=\"tweet\", ncols=100):\n",
    "    embeddings.append(get_roberta_embeddings(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d19b2e71-3ac3-426b-9771-5d3022783005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14640, 768)\n"
     ]
    }
   ],
   "source": [
    "# Convert the embeddings to a numpy array\n",
    "X = np.stack(embeddings)\n",
    "\n",
    "# Target labels\n",
    "y = df['sentiment_label'].values\n",
    "\n",
    "print(X.shape)  # Shape of the feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27aa2f65-2021-4e2a-823a-e777684a9e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 84.29%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91      1889\n",
      "     neutral       0.71      0.63      0.67       580\n",
      "    positive       0.79      0.74      0.77       459\n",
      "\n",
      "    accuracy                           0.84      2928\n",
      "   macro avg       0.80      0.77      0.78      2928\n",
      "weighted avg       0.84      0.84      0.84      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the dataset into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model on the BERT embeddings\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['negative', 'neutral', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21e8c8fe-29ec-4d48-b52b-8ad185f22488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: The flight was delayed by 2 hours. Terrible experience! \n",
      "Predicted Sentiment: negative\n",
      "\n",
      "Tweet: Great service, I loved the extra legroom in business class. \n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Tweet: The flight was fine, nothing special. \n",
      "Predicted Sentiment: negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example tweets to predict sentiment for\n",
    "new_tweets = [\n",
    "    \"The flight was delayed by 2 hours. Terrible experience!\",\n",
    "    \"Great service, I loved the extra legroom in business class.\",\n",
    "    \"The flight was fine, nothing special.\"\n",
    "]\n",
    "\n",
    "# Convert new tweets to BERT embeddings\n",
    "new_X = np.stack([get_roberta_embeddings(tweet) for tweet in new_tweets])\n",
    "\n",
    "# Predict sentiment for the new tweets\n",
    "new_predictions = clf.predict(new_X)\n",
    "\n",
    "# Map the predictions back to sentiment labels\n",
    "predicted_sentiments = ['negative' if pred == 0 else 'neutral' if pred == 1 else 'positive' for pred in new_predictions]\n",
    "\n",
    "# Display the results\n",
    "for tweet, sentiment in zip(new_tweets, predicted_sentiments):\n",
    "    print(f\"Tweet: {tweet} \\nPredicted Sentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0d6e7-95fb-41c0-884b-98f0089505ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
