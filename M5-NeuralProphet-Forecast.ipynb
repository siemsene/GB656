{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f661713b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import logging\n",
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "logging.getLogger('neuralprophet').setLevel(logging.WARNING)  # Suppress logs below WARNING\n",
    "\n",
    "# Disable logging messages unless there is an error\n",
    "set_log_level(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28bb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files\n",
    "data = pd.read_csv(\"C:/Data/M5store_2.csv\")\n",
    "\n",
    "# Ensure proper formatting\n",
    "data['ds'] = pd.to_datetime(data['d'])\n",
    "data = data.sort_values(by=['store_id', 'ds']).reset_index(drop=True)\n",
    "\n",
    "data.rename(columns={'revenue': 'y'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66720758-93b3-48a4-8f57-697ece2f930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table\n",
    "pivot_data = data.pivot(index='ds', columns='store_id', values='y')\n",
    "pivot_data.columns = [f'sales_store_{store}' for store in pivot_data.columns]\n",
    "\n",
    "# Merge the pivoted data with the original dataset\n",
    "data = pd.merge(\n",
    "    data, \n",
    "    pivot_data.reset_index(), \n",
    "    on=['ds'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop self-sales for each store\n",
    "for store in data['store_id'].unique():\n",
    "    feature_to_drop = f'sales_store_{store}'\n",
    "    data.loc[data['store_id'] == store, feature_to_drop] = None\n",
    "\n",
    "# Create lagged values for all columns starting with 'sales_store_'\n",
    "#for col in [col for col in data.columns if col.startswith('sales_store_')]:\n",
    "#    # Replace the column with its lagged version\n",
    "#    data[col] = data.groupby('store_id')[col].shift(1)  # Replace '1' with desired lag period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aa97758-5edf-4382-a15e-f7b0a2977c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total demand across all stores for each date\n",
    "total_demand = data.groupby('ds')['y'].sum().reset_index()\n",
    "total_demand.rename(columns={'y': 'total_sales_all_stores'}, inplace=True)\n",
    "\n",
    "# Merge total demand back into the original data\n",
    "data = pd.merge(data, total_demand, on='ds', how='left')\n",
    "\n",
    "# Subtract the current store's sales to get demand from other stores\n",
    "data['demand_other_stores'] = data['total_sales_all_stores'] - data['y']\n",
    "\n",
    "# Drop the intermediate column if not needed\n",
    "data.drop(columns=['total_sales_all_stores'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb7daf8b-d145-4500-87fd-93c852ea06bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['index'], inplace=True)\n",
    "data.drop(columns=['d'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3e1d135-8322-468d-9298-703433ca91dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19410 entries, 0 to 19409\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   store_id             19410 non-null  object        \n",
      " 1   y                    19410 non-null  float64       \n",
      " 2   sell_price           19410 non-null  float64       \n",
      " 3   ds                   19410 non-null  datetime64[ns]\n",
      " 4   demand_other_stores  19410 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(3), object(1)\n",
      "memory usage: 758.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bba30b06-653c-4800-a2f9-599c6fe35db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stores:   0%|                                                                        | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1bf0233cd443d4ab14e21c44477af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stores:  10%|██████▍                                                         | 1/10 [00:39<05:59, 39.98s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3ed77c20164f338bf3feff29112a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stores:  20%|████████████▊                                                   | 2/10 [01:17<05:09, 38.74s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568c400c823747a7a9ffdd93bb477ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stores:  30%|███████████████████▏                                            | 3/10 [01:56<04:29, 38.51s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e431c67cc68840cb97376cd299a9de2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stores:  40%|█████████████████████████▌                                      | 4/10 [02:34<03:49, 38.33s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4cf5134f324c3c9a5f9f627bcc0798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stores:  50%|████████████████████████████████                                | 5/10 [03:12<03:11, 38.20s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ce33d48e344dd5a749bf7b399c6a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stores:  60%|██████████████████████████████████████▍                         | 6/10 [03:50<02:32, 38.12s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2d1ecdc4924333a738bfed6abafcf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stores:  70%|████████████████████████████████████████████▊                   | 7/10 [04:28<01:54, 38.11s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32217d99675343f09e1ef6cc7cea9f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stores:  80%|███████████████████████████████████████████████████▏            | 8/10 [05:06<01:16, 38.13s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d7502a822b4e80b1ccd1d4138850b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stores:  90%|█████████████████████████████████████████████████████████▌      | 9/10 [05:44<00:38, 38.07s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0993b55821a48788784c670eb3245f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stores: 100%|███████████████████████████████████████████████████████████████| 10/10 [06:22<00:00, 38.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             MASE\n",
      "CA_1     0.584234\n",
      "CA_2     0.877810\n",
      "CA_3     0.708761\n",
      "CA_4     0.793601\n",
      "TX_1     0.563215\n",
      "TX_2     0.324389\n",
      "TX_3     0.812571\n",
      "WI_1     0.653963\n",
      "WI_2     1.028290\n",
      "WI_3     1.107245\n",
      "Average  0.745408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralprophet import NeuralProphet\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_mase(y_true, y_pred, y_train):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Absolute Scaled Error (MASE).\n",
    "    \"\"\"\n",
    "    mae_forecast = np.mean(np.abs(y_true - y_pred))\n",
    "    mae_naive = np.mean(np.abs(y_train[1:] - y_train[:-1]))\n",
    "    return mae_forecast / mae_naive\n",
    "\n",
    "# Initialize results\n",
    "mase_scores = []\n",
    "store_results = {}\n",
    "\n",
    "# Parameters\n",
    "m = 28  # Number of observations to leave out for validation\n",
    "h = 14   # Forecast horizon\n",
    "n = m - h  # Number of rolling forecasts to generate\n",
    "\n",
    "# Iterate over each store\n",
    "for store in tqdm(data['store_id'].unique(), desc=\"Processing stores\"):\n",
    "    store_data = data[data['store_id'] == store].copy()\n",
    "    store_data = store_data.sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "    model = NeuralProphet(\n",
    "        n_lags=7,\n",
    "        n_forecasts=h,\n",
    "        ar_layers=[16, 16],\n",
    "        yearly_seasonality=True,\n",
    "        weekly_seasonality=True,\n",
    "        daily_seasonality=False,\n",
    "        n_changepoints=10,\n",
    "        changepoints_range=0.8)\n",
    "    model.add_country_holidays(\"US\")\n",
    "    model.add_future_regressor(\"sell_price\")\n",
    "    model.add_lagged_regressor(\"demand_other_stores\", n_lags=1)\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    train_data = store_data.iloc[:-m]\n",
    "    #test_data = store_data.iloc[-m:]\n",
    "    #test_data = test_data.reset_index(drop=True)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_data[['ds', 'y', 'sell_price', 'demand_other_stores']], freq=\"D\", minimal=True, epochs=120)\n",
    "    \n",
    "    # Rolling forecast\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        forecast_data = store_data.iloc[:-m + i + h].copy()\n",
    "\n",
    "        # Make forecast\n",
    "        forecast = model.predict(forecast_data[['ds', 'y', 'sell_price', 'demand_other_stores']])\n",
    "        y_pred = forecast.iloc[-1][f\"yhat{h}\"]\n",
    "        y_true = forecast.iloc[-1]['y']\n",
    "        \n",
    "        # Store true and predicted values\n",
    "        y_preds.append(y_pred)\n",
    "        y_trues.append(y_true)\n",
    "        #y_trues.append(test_data.iloc[h + i - 1]['y'])\n",
    "    \n",
    "    # Calculate MASE for the store\n",
    "    mase = calculate_mase(np.array(y_trues), np.array(y_preds), train_data['y'].values)\n",
    "    store_results[store] = mase\n",
    "    mase_scores.append(mase)\n",
    "\n",
    "# Calculate the average MASE across all stores\n",
    "average_mase = np.mean(mase_scores)\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "store_results_df = pd.DataFrame.from_dict(store_results, orient='index', columns=['MASE'])\n",
    "store_results_df.loc['Average'] = average_mase\n",
    "\n",
    "# Display the results\n",
    "print(store_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4fb3a2-f996-4a7a-8d9c-6f46dd4bdfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
